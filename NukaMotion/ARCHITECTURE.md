# NukaMotion Architecture

Motion + Agent Coordination Design

---

## Overview

NukaMotion consists of **two tightly-coupled subsystems**:

1. **Motion Perception System** (MoveNet-based squat detection)
2. **Agent & Alarm System** (Nuka Agent powered by Qwen LLM)

They communicate through a **local HTTP interface**, allowing real-time motion
events to control alarm state deterministically.

---

## High-Level Components

```
+-------------------+        HTTP (POST /rep)
|                   |  -------------------->
|   Motion Engine   |                        |
|  (MoveNet + CV)   |                        |
|                   |  <--------------------
+-------------------+        HTTP (GET /status)
           |
           |  Squat Detected
           v
+-------------------+
| Squat State Machine|
|  STAND/DOWN/COUNT |
+-------------------+
```

```
+----------------------------+
|        Nuka Agent          |
|----------------------------|
| - Alarm Scheduler          |
| - SQLite Persistence       |
| - Session State Machine    |
| - LLM Intent Parser        |
| - Audio Control Logic      |
+----------------------------+
```

---

## Alarm Lifecycle

```
IDLE
 |
 | (Alarm Time Reached)
 v
RINGING  <-- alarm sound looping
 |
 | (Human motion detected)
 v
SQUAT_ACTIVE  <-- alarm muted, counting reps
 |
 | (Reps completed)
 v
UNLOCKED
 |
 | (Stop confirmed)
 v
DONE
```

Key rule:
- **Alarm sound resumes automatically** if motion stops before completion.

---

## Motion â†’ Agent Timing Flow

```
Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>

[ Alarm rings ]
      ğŸ”ŠğŸ”ŠğŸ”ŠğŸ”ŠğŸ”Š

User starts squatting
      |
      v
MoveNet detects DOWN â†’ STAND
      |
      v
POST /rep
      |
      v
NukaCore.report_rep()
      |
      v
rep_count += 1
      |
      v
ğŸ”” "ding" sound

(repeat)

If motion stops > timeout:
      |
      v
Alarm resumes ğŸ”Š

If reps == target:
      |
      v
Alarm permanently stops
      |
      v
LLM encouragement (once)
```

---

## Motion Engine Details

**Input**
- USB Camera (side view)

**Pipeline**
```
Frame
 â†’ Letterbox Resize
   â†’ MoveNet Inference
     â†’ Keypoints
       â†’ Knee Angle
         â†’ EMA Smoothing
           â†’ Squat State Machine
```

**Output**
- `SQUAT_DONE` event
- Triggers HTTP POST `/rep`

---

## Agent Responsibilities

### Deterministic (No LLM)
- Alarm scheduling
- Squat counting
- Alarm enforcement
- Audio timing
- Timeout handling
- Persistence (SQLite)

### LLM-Assisted (Qwen via Ollama)
Used **only where ambiguity exists**:

| Task | LLM |
|----|----|
| Parse natural language commands | âœ… |
| Convert intent â†’ JSON | âœ… |
| Generate encouragement text | âœ… |
| Alarm timing logic | âŒ |
| Squat counting | âŒ |

This guarantees **real-time safety** and **low latency**.

---

## Why This Architecture Works

- Motion system runs at camera frame rate
- Agent logic remains deterministic
- LLM is never in the critical path
- Clear separation of perception vs decision
- Easy to extend with new motion types

---

## Future Extensions

- GPU/TensorRT inference
- Multiple motion types (jump, plank)
- BLE / wearable integration
- Smart speaker / TTS output
- Cloud-free offline mode

---

**Motion proves wakefulness.**
